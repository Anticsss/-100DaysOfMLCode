{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification with sklearn breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing weights and bias\n",
    "def initialiseNetwork(num_features):\n",
    "  W = np.zeros((num_features, 1))\n",
    "  b = 0\n",
    "  parameters = {\"W\": W, \"b\": b}\n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining sigmoid function\n",
    "def sigmoid(z):\n",
    "  a = 1/(1 + np.exp(-z))\n",
    "  return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining forward propagation function\n",
    "def forwardPropagation(X, parameters):\n",
    "  W = parameters[\"W\"]\n",
    "  b = parameters[\"b\"]\n",
    "  Z = np.dot(W.T,X) + b\n",
    "  A = sigmoid(Z)\n",
    "  return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining cost function\n",
    "def cost(A, Y, num_samples):\n",
    "  cost = -1/num_samples *np.sum(Y*np.log(A) + (1-Y)*(np.log(1-A)))\n",
    "  return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining backpropagation function\n",
    "def backPropagration(X, Y, A, num_samples):\n",
    "  dZ = A - Y                          \n",
    "  dW = (np.dot(X,dZ.T))/num_samples   #(X dot_product dZ.T)/num_samples\n",
    "  db = np.sum(dZ)/num_samples         #sum(dZ)/num_samples\n",
    "  return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update parameters\n",
    "def updateParameters(parameters, dW, db, learning_rate):\n",
    "  W = parameters[\"W\"] - (learning_rate * dW)\n",
    "  b = parameters[\"b\"] - (learning_rate * db)\n",
    "  return {\"W\": W, \"b\": b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model\n",
    "def model(X, Y, num_iter, learning_rate):\n",
    "  num_features = X.shape[0]\n",
    "  num_samples = X.shape[1]\n",
    "  parameters = initialiseNetwork(num_features)                     #call initialiseNetwork()\n",
    "  for i in range(num_iter):\n",
    "    A = forwardPropagation(X, parameters)                       # calculate final output A from forwardPropagation()\n",
    "    if(i%100 == 0):\n",
    "      print(\"cost after {} iteration: {}\".format(i, cost(A, Y, num_samples)))\n",
    "    dW, db = backPropagration(X, Y, A, num_samples)                # calculate  derivatives from backpropagation\n",
    "    parameters = updateParameters(parameters, dW, db, learning_rate)    # update parameters\n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining prediction function\n",
    "def predict(W, b, X):\n",
    "  Z = np.dot(W.T,X) + b\n",
    "  Y = np.array([1 if y > 0.5 else 0 for y in sigmoid(Z[0])]).reshape(1,len(Z[0]))\n",
    "  return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer, y_cancer = load_breast_cancer(return_X_y = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize data\n",
    "def normalize(data):\n",
    "  col_max = np.max(data, axis = 0)\n",
    "  col_min = np.min(data, axis = 0)\n",
    "  return np.divide(data - col_min, col_max - col_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n = normalize(X_train)\n",
    "X_test_n = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainT = X_train_n.T\n",
    "X_testT = X_test_n.T\n",
    "y_trainT = y_train.reshape(1, 426)\n",
    "y_testT = y_test.reshape(1, 143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 0 iteration: 0.6931471805599453\n",
      "cost after 100 iteration: 0.24382767353051085\n",
      "cost after 200 iteration: 0.18414919195134818\n",
      "cost after 300 iteration: 0.1565873493485997\n",
      "cost after 400 iteration: 0.1396752246321806\n",
      "cost after 500 iteration: 0.1278729526958286\n",
      "cost after 600 iteration: 0.1190088775113677\n",
      "cost after 700 iteration: 0.11202667072700777\n",
      "cost after 800 iteration: 0.10633924623930974\n",
      "cost after 900 iteration: 0.10158933661241841\n",
      "cost after 1000 iteration: 0.09754476494426205\n",
      "cost after 1100 iteration: 0.0940469433647547\n",
      "cost after 1200 iteration: 0.09098323338346236\n",
      "cost after 1300 iteration: 0.08827107206470108\n",
      "cost after 1400 iteration: 0.08584834873491791\n",
      "cost after 1500 iteration: 0.08366730760137953\n",
      "cost after 1600 iteration: 0.08169053991796828\n",
      "cost after 1700 iteration: 0.07988826663984765\n",
      "cost after 1800 iteration: 0.07823644647304043\n",
      "cost after 1900 iteration: 0.07671542796224082\n",
      "cost after 2000 iteration: 0.07530896965280098\n",
      "cost after 2100 iteration: 0.0740035150406475\n",
      "cost after 2200 iteration: 0.07278764749502994\n",
      "cost after 2300 iteration: 0.0716516746189091\n",
      "cost after 2400 iteration: 0.0705873072187579\n",
      "cost after 2500 iteration: 0.06958740844345282\n",
      "cost after 2600 iteration: 0.06864579565976343\n",
      "cost after 2700 iteration: 0.06775708244509038\n",
      "cost after 2800 iteration: 0.06691655143817629\n",
      "cost after 2900 iteration: 0.06612005116932484\n",
      "cost after 3000 iteration: 0.06536391170175201\n",
      "cost after 3100 iteration: 0.06464487515951275\n",
      "cost after 3200 iteration: 0.06396003813267387\n",
      "cost after 3300 iteration: 0.06330680363111521\n",
      "cost after 3400 iteration: 0.06268284076971896\n",
      "cost after 3500 iteration: 0.06208605075546861\n",
      "cost after 3600 iteration: 0.06151453804358737\n",
      "cost after 3700 iteration: 0.060966585758594094\n",
      "cost after 3800 iteration: 0.06044063465393139\n",
      "cost after 3900 iteration: 0.05993526502299061\n",
      "cost after 4000 iteration: 0.05944918108405797\n",
      "cost after 4100 iteration: 0.05898119744873463\n",
      "cost after 4200 iteration: 0.05853022735285599\n",
      "cost after 4300 iteration: 0.05809527238471592\n",
      "cost after 4400 iteration: 0.057675413490439746\n",
      "cost after 4500 iteration: 0.0572698030729034\n",
      "cost after 4600 iteration: 0.05687765803041879\n",
      "cost after 4700 iteration: 0.056498253605847336\n",
      "cost after 4800 iteration: 0.05613091793693274\n",
      "cost after 4900 iteration: 0.05577502721529133\n",
      "train accuracy: 98.82629107981221%\n",
      "test accuracy: 93.00699300699301%\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_trainT, y_trainT, num_iter=5000, learning_rate=0.75)                        #call the model() function with parametrs mentioned in the above cell\n",
    "\n",
    "yPredTrain = predict(parameters['W'], parameters['b'], X_trainT)   # pass weigths and bias from parameters dictionary and X_trainT as input to the function\n",
    "yPredTest = predict(parameters['W'], parameters['b'], X_testT)    # pass the same parameters but X_testT as input data\n",
    "\n",
    "accuracy_train = 100 - np.mean(np.abs(yPredTrain - y_trainT)) * 100\n",
    "accuracy_test = 100 - np.mean(np.abs(yPredTest - y_testT)) * 100\n",
    "print(\"train accuracy: {}%\".format(accuracy_train))\n",
    "print(\"test accuracy: {}%\".format(accuracy_test))\n",
    "with open(\"Output.txt\", \"w\") as text_file:\n",
    "  text_file.write(\"train= %f\\n\" % accuracy_train)\n",
    "  text_file.write(\"test= %f\" % accuracy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
